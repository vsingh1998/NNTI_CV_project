2022-03-02 01:06:35,299 - root - INFO - ==>>> epoch: 0, train loss: 2.3482013940811157, train accuracy: tensor([6.2500])
2022-03-02 01:06:50,995 - root - INFO - ==>>> epoch: 1, train loss: 2.153348207473755, train accuracy: tensor([42.5781])
2022-03-02 01:11:36,323 - root - INFO - ==>>> epoch: 0, train loss: 2.3079949617385864, train accuracy: tensor([10.9375])
2022-03-02 01:11:50,483 - root - INFO - ==>>> epoch: 1, train loss: 2.159042239189148, train accuracy: tensor([44.1406])
2022-03-02 01:13:56,753 - root - INFO - ==>>> epoch: 0, train loss: 2.3394815921783447, train accuracy: tensor([10.9375])
2022-03-02 01:14:10,854 - root - INFO - ==>>> epoch: 1, train loss: 2.0763370990753174, train accuracy: tensor([51.5625])
2022-03-02 01:15:15,904 - root - INFO - ==>>> epoch: 0, train loss: 2.3209201097488403, train accuracy: tensor([10.1562])
2022-03-02 01:15:30,014 - root - INFO - ==>>> epoch: 1, train loss: 2.1283448934555054, train accuracy: tensor([26.5625])
2022-03-02 01:18:39,326 - root - INFO - ==>>> epoch: 0, train loss: 2.342016100883484, train accuracy: tensor([7.8125])
2022-03-02 01:18:53,601 - root - INFO - ==>>> epoch: 1, train loss: 2.1702303886413574, train accuracy: tensor([41.0156])
2022-03-02 01:20:29,699 - root - INFO - ==>>> epoch: 0, train loss: 2.3137916326522827, train accuracy: tensor([10.9375])
2022-03-02 01:20:43,911 - root - INFO - ==>>> epoch: 1, train loss: 2.1985971927642822, train accuracy: tensor([35.1562])
2022-03-02 13:47:45,600 - root - INFO - ==>>> epoch: 0, train loss: 2.298723578453064, train accuracy: tensor([3.9062])
2022-03-02 13:48:18,841 - root - INFO - ==>>> epoch: 1, train loss: 2.21901535987854, train accuracy: tensor([26.9531])
2022-03-02 13:55:30,375 - root - INFO - ==>>> epoch: 0, train loss: 2.350080728530884, train accuracy: tensor([9.3750])
2022-03-02 13:55:59,455 - root - INFO - ==>>> epoch: 1, train loss: 2.105965495109558, train accuracy: tensor([52.7344])
2022-03-02 14:02:27,867 - root - INFO - ==>>> epoch: 0, train loss: 2.320454955101013, train accuracy: tensor([10.1562])
2022-03-02 14:03:05,442 - root - INFO - ==>>> epoch: 1, train loss: 2.164185404777527, train accuracy: tensor([47.2656])
2022-03-02 14:04:28,200 - root - INFO - ==>>> epoch: 0, train loss: 2.312036633491516, train accuracy: tensor([11.7188])
2022-03-02 14:05:06,472 - root - INFO - ==>>> epoch: 1, train loss: 2.0978087186813354, train accuracy: tensor([57.0312])
2022-03-02 14:06:34,175 - root - INFO - ==>>> epoch: 0, train loss: 2.3116257190704346, train accuracy: tensor([11.7188])
2022-03-02 14:07:14,223 - root - INFO - ==>>> epoch: 1, train loss: 2.2109261751174927, train accuracy: tensor([29.2969])
2022-03-02 14:08:54,826 - root - INFO - ==>>> epoch: 0, train loss: 2.342276096343994, train accuracy: tensor([8.5938])
2022-03-02 14:09:35,573 - root - INFO - ==>>> epoch: 1, train loss: 2.0995014905929565, train accuracy: tensor([39.4531])
2022-03-02 14:18:17,418 - root - INFO - ==>>> test accuracy: 12.530048076923077
2022-03-03 23:42:04,980 - root - INFO - ==>>> epoch: 0, train loss: 2.3058829307556152, train accuracy: tensor([17.1875])
2022-03-03 23:42:11,749 - root - INFO - ==>>> epoch: 1, train loss: 2.339081287384033, train accuracy: tensor([7.8125])
2022-03-03 23:47:03,840 - root - INFO - ==>>> epoch: 0, train loss: 2.3392508029937744, train accuracy: tensor([9.3750])
2022-03-03 23:47:11,345 - root - INFO - ==>>> epoch: 1, train loss: 2.3542885780334473, train accuracy: tensor([6.2500])
2022-03-03 23:48:37,872 - root - INFO - ==>>> epoch: 0, train loss: 2.362211227416992, train accuracy: tensor([10.9375])
2022-03-03 23:48:44,498 - root - INFO - ==>>> epoch: 1, train loss: 2.4121525287628174, train accuracy: tensor([3.1250])
2022-03-03 23:49:45,332 - root - INFO - ==>>> epoch: 0, train loss: 2.3127145767211914, train accuracy: tensor([14.0625])
2022-03-03 23:49:51,754 - root - INFO - ==>>> epoch: 1, train loss: 2.324467182159424, train accuracy: tensor([9.3750])
2022-03-03 23:59:50,077 - root - INFO - ==>>> epoch: 0, train loss: 2.334646701812744, train accuracy: tensor([7.8125])
2022-03-03 23:59:56,253 - root - INFO - ==>>> epoch: 1, train loss: 2.3352365493774414, train accuracy: tensor([9.3750])
2022-03-04 23:36:39,691 - root - INFO - ==>>> epoch: 0, train loss: 2.3129999240239463, train accuracy: tensor([11.1979])
2022-03-04 23:37:24,031 - root - INFO - ==>>> epoch: 1, train loss: 2.275736451148987, train accuracy: tensor([17.9688])
2022-03-04 23:40:14,808 - root - INFO - ==>>> epoch: 0, train loss: 2.313636541366577, train accuracy: tensor([12.5000])
2022-03-04 23:40:21,342 - root - INFO - ==>>> epoch: 1, train loss: 2.360869884490967, train accuracy: tensor([6.2500])
2022-03-04 23:42:12,519 - root - INFO - ==>>> epoch: 0, train loss: 2.2982633113861084, train accuracy: tensor([23.4375])
2022-03-04 23:42:19,339 - root - INFO - ==>>> epoch: 1, train loss: 2.3356711864471436, train accuracy: tensor([7.8125])
2022-03-04 23:42:37,975 - root - INFO - ==>>> similarity loss: 0.9662391543388367
2022-03-04 23:43:02,037 - root - INFO - ==>>> similarity loss: 0.980910062789917
2022-03-04 23:43:04,575 - root - INFO - ==>>> similarity loss: 0.980910062789917
2022-03-04 23:43:17,550 - root - INFO - ==>>> similarity loss: 0.980910062789917
2022-03-04 23:43:41,556 - root - INFO - ==>>> epoch: 0, train loss: 2.2891666889190674, train accuracy: tensor([10.9375])
2022-03-04 23:43:48,442 - root - INFO - ==>>> epoch: 1, train loss: 2.3252832889556885, train accuracy: tensor([9.3750])
2022-03-04 23:44:05,065 - root - INFO - ==>>> similarity loss: 0.991516649723053
2022-03-04 23:44:20,951 - root - INFO - ==>>> similarity loss: 0.9897196292877197
2022-03-04 23:44:22,484 - root - INFO - ==>>> similarity loss: 0.9897196292877197
2022-03-04 23:44:29,177 - root - INFO - ==>>> similarity loss: 0.9897196292877197
2022-03-04 23:49:02,555 - root - INFO - ==>>> test accuracy: 10.126201923076923
2022-03-05 22:43:28,044 - root - INFO - ==>>> epoch: 0, train loss: 2.363679885864258, train accuracy: tensor([7.8125])
2022-03-05 22:43:38,475 - root - INFO - ==>>> epoch: 1, train loss: 2.409454822540283, train accuracy: tensor([4.6875])
2022-03-05 22:54:25,107 - root - INFO - ==>>> epoch: 0, train loss: 2.395172119140625, train accuracy: tensor([7.8125])
2022-03-05 22:54:40,913 - root - INFO - ==>>> epoch: 1, train loss: 2.3749096393585205, train accuracy: tensor([7.8125])
2022-03-05 23:11:49,746 - root - INFO - ==>>> epoch: 0, train loss: 2.2864527702331543, train accuracy: tensor([10.9375])
2022-03-05 23:12:14,606 - root - INFO - ==>>> epoch: 1, train loss: 2.285830497741699, train accuracy: tensor([20.3125])
2022-03-05 23:12:53,036 - root - INFO - ==>>> similarity loss: 0.9752877950668335
2022-03-05 23:13:43,728 - root - INFO - ==>>> similarity loss: 0.9663993120193481
2022-03-05 23:13:48,930 - root - INFO - ==>>> similarity loss: 0.9663993120193481
2022-03-05 23:14:15,822 - root - INFO - ==>>> similarity loss: 0.9663993120193481
2022-03-05 23:15:13,129 - root - INFO - ==>>> epoch: 0, train loss: 2.335218667984009, train accuracy: tensor([10.9375])
2022-03-05 23:15:30,597 - root - INFO - ==>>> epoch: 1, train loss: 2.3176558017730713, train accuracy: tensor([10.9375])
2022-03-05 23:32:57,772 - root - INFO - ==>>> epoch: 0, train loss: 2.31017804145813, train accuracy: tensor([7.8125])
2022-03-05 23:33:10,945 - root - INFO - ==>>> epoch: 1, train loss: 2.2958099842071533, train accuracy: tensor([14.0625])
2022-03-05 23:35:01,131 - root - INFO - ==>>> epoch: 0, train loss: 2.3326752185821533, train accuracy: tensor([7.8125])
2022-03-05 23:35:20,531 - root - INFO - ==>>> epoch: 1, train loss: 2.30033540725708, train accuracy: tensor([10.9375])
2022-03-05 23:37:25,425 - root - INFO - ==>>> epoch: 0, train loss: 2.3837451934814453, train accuracy: tensor([6.2500])
2022-03-05 23:37:40,451 - root - INFO - ==>>> epoch: 1, train loss: 2.3376803398132324, train accuracy: tensor([12.5000])
2022-03-05 23:39:19,138 - root - INFO - ==>>> epoch: 0, train loss: 2.3338546752929688, train accuracy: tensor([4.6875])
2022-03-05 23:39:35,919 - root - INFO - ==>>> epoch: 1, train loss: 2.3195087909698486, train accuracy: tensor([4.6875])
2022-03-05 23:48:08,146 - root - INFO - ==>>> epoch: 0, train loss: 2.307478189468384, train accuracy: tensor([4.6875])
2022-03-05 23:48:16,835 - root - INFO - ==>>> epoch: 1, train loss: 2.3017685413360596, train accuracy: tensor([14.0625])
2022-03-05 23:51:55,387 - root - INFO - ==>>> epoch: 0, train loss: 2.3757452964782715, train accuracy: tensor([9.3750])
2022-03-05 23:52:13,547 - root - INFO - ==>>> epoch: 1, train loss: 2.4030182361602783, train accuracy: tensor([6.2500])
2022-03-05 23:53:17,439 - root - INFO - ==>>> epoch: 0, train loss: 2.307988405227661, train accuracy: tensor([12.5000])
2022-03-05 23:53:32,249 - root - INFO - ==>>> epoch: 1, train loss: 2.2764036655426025, train accuracy: tensor([20.3125])
2022-03-05 23:53:58,965 - root - INFO - ==>>> epoch: 0, train loss: 2.3131229877471924, train accuracy: tensor([18.7500])
2022-03-05 23:54:19,097 - root - INFO - ==>>> epoch: 1, train loss: 2.3235409259796143, train accuracy: tensor([12.5000])
2022-03-05 23:54:54,165 - root - INFO - ==>>> similarity loss: 0.9956465363502502
2022-03-05 23:55:30,348 - root - INFO - ==>>> similarity loss: 0.9958095550537109
2022-03-05 23:55:34,152 - root - INFO - ==>>> similarity loss: 0.9958095550537109
2022-03-05 23:55:48,996 - root - INFO - ==>>> similarity loss: 0.9958095550537109
2022-03-06 00:04:20,949 - root - INFO - ==>>> test accuracy: 10.106169871794872
2022-03-07 23:35:32,391 - root - INFO - ==>>> similarity loss: 0.9666174054145813
2022-03-07 23:35:56,809 - root - INFO - ==>>> similarity loss: 0.9689314365386963
2022-03-07 23:35:58,003 - root - INFO - ==>>> similarity loss: 0.9689314365386963
2022-03-07 23:35:59,895 - root - INFO - ==>>> similarity loss: 0.9689314365386963
2022-03-07 23:39:58,151 - root - INFO - ==>>> test accuracy: 9.835737179487179
2022-03-08 16:20:11,037 - root - INFO - ==>>> similarity loss: 0.773266613483429
2022-03-08 16:21:42,001 - root - INFO - ==>>> similarity loss: 0.8889862298965454
2022-03-08 16:21:46,930 - root - INFO - ==>>> similarity loss: 0.8753514289855957
2022-03-08 16:21:49,341 - root - INFO - ==>>> similarity loss: 0.8753514289855957
2022-03-08 16:21:51,765 - root - INFO - ==>>> similarity loss: 0.7947332859039307
2022-03-08 16:21:59,184 - root - INFO - ==>>> similarity loss: 0.7592910528182983
2022-03-08 16:22:04,590 - root - INFO - ==>>> similarity loss: 0.7592910528182983
2022-03-08 16:22:09,307 - root - INFO - ==>>> similarity loss: 0.8301177024841309
2022-03-08 16:22:25,080 - root - INFO - ==>>> similarity loss: 0.738572359085083
2022-03-08 16:22:33,889 - root - INFO - ==>>> similarity loss: 0.738572359085083
2022-03-08 16:22:35,499 - root - INFO - ==>>> similarity loss: 0.6092888116836548
2022-03-08 16:22:40,486 - root - INFO - ==>>> similarity loss: 0.6639285087585449
2022-03-08 16:22:45,778 - root - INFO - ==>>> similarity loss: 0.6639285087585449
2022-03-08 16:22:48,981 - root - INFO - ==>>> similarity loss: 0.40776118636131287
2022-03-08 16:22:58,444 - root - INFO - ==>>> similarity loss: 0.4038175344467163
2022-03-08 16:23:04,185 - root - INFO - ==>>> similarity loss: 0.4038175344467163
2022-03-08 16:23:07,198 - root - INFO - ==>>> similarity loss: 0.4483693838119507
2022-03-08 16:23:16,112 - root - INFO - ==>>> similarity loss: 0.15782426297664642
2022-03-08 16:23:21,079 - root - INFO - ==>>> similarity loss: 0.15782426297664642
2022-03-08 16:23:22,414 - root - INFO - ==>>> similarity loss: 0.15782426297664642
2022-03-08 16:23:24,584 - root - INFO - ==>>> similarity loss: 0.15782426297664642
2022-03-08 16:27:36,822 - root - INFO - ==>>> similarity loss: 0.7941453456878662
2022-03-08 16:27:46,048 - root - INFO - ==>>> similarity loss: 0.8975801467895508
2022-03-08 16:27:48,549 - root - INFO - ==>>> similarity loss: 0.8975801467895508
2022-03-08 16:27:51,575 - root - INFO - ==>>> similarity loss: 0.8391467332839966
2022-03-08 16:27:59,569 - root - INFO - ==>>> similarity loss: 0.703362226486206
2022-03-08 16:28:02,069 - root - INFO - ==>>> similarity loss: 0.703362226486206
2022-03-08 16:28:03,289 - root - INFO - ==>>> similarity loss: 0.827659547328949
2022-03-08 16:28:08,262 - root - INFO - ==>>> similarity loss: 0.7683912515640259
2022-03-08 16:28:14,251 - root - INFO - ==>>> similarity loss: 0.7683912515640259
2022-03-08 16:28:15,389 - root - INFO - ==>>> similarity loss: 0.7683912515640259
2022-03-08 16:28:17,542 - root - INFO - ==>>> similarity loss: 0.7683912515640259
2022-03-08 16:28:19,711 - root - INFO - ==>>> similarity loss: 0.7683912515640259
2022-03-08 16:28:21,917 - root - INFO - ==>>> similarity loss: 0.7683912515640259
2022-03-08 16:28:24,059 - root - INFO - ==>>> similarity loss: 0.7683912515640259
2022-03-08 16:29:17,841 - root - INFO - ==>>> similarity loss: 0.8265272974967957
2022-03-08 16:29:28,754 - root - INFO - ==>>> similarity loss: 0.7413646578788757
2022-03-08 16:29:31,391 - root - INFO - ==>>> similarity loss: 0.7413646578788757
2022-03-08 16:29:33,799 - root - INFO - ==>>> similarity loss: 0.7810807228088379
2022-03-08 16:29:40,612 - root - INFO - ==>>> similarity loss: 0.8177782893180847
2022-03-08 16:29:44,771 - root - INFO - ==>>> similarity loss: 0.8177782893180847
2022-03-08 16:29:48,921 - root - INFO - ==>>> similarity loss: 0.8096949458122253
2022-03-08 16:29:56,184 - root - INFO - ==>>> similarity loss: 0.8096949458122253
2022-03-08 16:29:57,008 - root - INFO - ==>>> classifier_loss: 2.3428773880004883
2022-03-08 16:29:57,605 - root - INFO - ==>>> similarity loss: 0.8096949458122253
2022-03-08 16:29:58,154 - root - INFO - ==>>> classifier_loss: 2.3057775497436523
2022-03-08 16:29:59,290 - root - INFO - ==>>> classifier_loss: 2.3004462718963623
2022-03-08 16:29:59,889 - root - INFO - ==>>> similarity loss: 0.8096949458122253
2022-03-08 16:30:00,397 - root - INFO - ==>>> classifier_loss: 2.2666025161743164
2022-03-08 16:30:01,537 - root - INFO - ==>>> classifier_loss: 2.2525691986083984
2022-03-08 16:30:02,126 - root - INFO - ==>>> similarity loss: 0.8096949458122253
2022-03-08 16:30:02,695 - root - INFO - ==>>> classifier_loss: 2.2850043773651123
2022-03-08 16:30:03,766 - root - INFO - ==>>> classifier_loss: 2.3177671432495117
2022-03-08 16:30:04,414 - root - INFO - ==>>> similarity loss: 0.8096949458122253
2022-03-08 16:30:04,947 - root - INFO - ==>>> classifier_loss: 2.2752888202667236
2022-03-08 16:30:06,011 - root - INFO - ==>>> classifier_loss: 2.2593846321105957
2022-03-08 16:30:06,680 - root - INFO - ==>>> similarity loss: 0.8096949458122253
2022-03-08 16:34:45,583 - root - INFO - ==>>> test accuracy: 10.026041666666666
